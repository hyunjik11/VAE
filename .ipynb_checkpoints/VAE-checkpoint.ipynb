{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\")\n",
    "n_train_samples = mnist.train.num_examples\n",
    "n_valid_samples = mnist.validation.num_examples\n",
    "n_samples = n_train_samples + n_valid_samples\n",
    "n_test_samples = mnist.test.num_examples\n",
    "# using images with pixel values in {0,1}. i.e. p(x|z) is bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xavier_init(fan_in, fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), \n",
    "                             minval=low, maxval=high, \n",
    "                             dtype=tf.float32)\n",
    "\n",
    "def gauss_init(n_params,stddev=1): #initialise params by Gaussians\n",
    "    return tf.random_normal([n_params],stddev=stddev,dtype=tf.float32)\n",
    "\n",
    "def convert_col_idx(n_z,idx): \n",
    "# convert col indices of 2D array with n_z rows to indices for flattened vector\n",
    "    ncol=len(idx)\n",
    "    indices=np.empty(n_z*ncol,dtype=int)\n",
    "    for i in xrange(0,ncol):\n",
    "        indices[i*n_z:(i+1)*n_z]=np.arange(idx[i]*n_z,(idx[i]+1)*n_z)\n",
    "    return indices\n",
    "\n",
    "def bernoullisample(x):\n",
    "    return np.random.binomial(1,x,size=x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(object):\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "    \n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian \n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "    \n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture, transfer_fct=tf.nn.softplus, \n",
    "                 learning_rate=0.001, batch_size=100):\n",
    "        self.network_architecture = network_architecture\n",
    "        self.transfer_fct = transfer_fct\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # tf Graph input (placeholder objects can only be used as input, and can't be evaluated)\n",
    "        self.x = tf.placeholder(tf.float32, [None, network_architecture[\"n_input\"]])\n",
    "        \n",
    "        # Create autoencoder network\n",
    "        self._create_network()\n",
    "        # Define loss function based variational upper-bound and \n",
    "        # corresponding optimizer\n",
    "        self._create_loss_optimizer()\n",
    "        \n",
    "        # Initializing the tensorflow variables\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "        # Launch the session\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init) # initialize all tensorflow variables\n",
    "    \n",
    "    def _create_network(self):\n",
    "        # Initialize autoencode network weights and biases\n",
    "        network_weights = self._initialize_weights(**self.network_architecture)\n",
    "        # this feeds in the values of self.network_architecture as arguments to _initialize_weights\n",
    "        \n",
    "        # Use recognition network to determine mean and \n",
    "        # (log) variance of Gaussian distribution in latent\n",
    "        # space\n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self._recognition_network(network_weights[\"weights_recog\"], \n",
    "                                      network_weights[\"biases_recog\"])\n",
    "\n",
    "        # Draw one sample z from Gaussian distribution\n",
    "        # n_z is dimensionality of latent space\n",
    "        n_z = self.network_architecture[\"n_z\"]\n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, \n",
    "                               dtype=tf.float32)\n",
    "        # z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, \n",
    "                        tf.mul(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "\n",
    "        # Use generator to determine mean of\n",
    "        # Bernoulli distribution of reconstructed input\n",
    "        self.x_reconstr_mean = \\\n",
    "            self._generator_network(network_weights[\"weights_gener\"],\n",
    "                                    network_weights[\"biases_gener\"])\n",
    "            \n",
    "    def _initialize_weights(self, n_hidden_recog_1, n_hidden_recog_2, \n",
    "                            n_hidden_gener_1,  n_hidden_gener_2, \n",
    "                            n_input, n_z):\n",
    "        # initialize weights, stored in dictionary all_weights (member of VAE class)\n",
    "        # these are all the variables that will be learned\n",
    "        # Use Xaiver init for weights, 0 for biases\n",
    "        all_weights = dict()\n",
    "        all_weights['weights_recog'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_input, n_hidden_recog_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_recog_1, n_hidden_recog_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_recog_2, n_z)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_recog_2, n_z))}\n",
    "        all_weights['biases_recog'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_recog_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_recog_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_z], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_z], dtype=tf.float32))}\n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(xavier_init(n_z, n_hidden_gener_1)),\n",
    "            'h2': tf.Variable(xavier_init(n_hidden_gener_1, n_hidden_gener_2)),\n",
    "            'out_mean': tf.Variable(xavier_init(n_hidden_gener_2, n_input)),\n",
    "            'out_log_sigma': tf.Variable(xavier_init(n_hidden_gener_2, n_input))}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(tf.zeros([n_hidden_gener_1], dtype=tf.float32)),\n",
    "            'b2': tf.Variable(tf.zeros([n_hidden_gener_2], dtype=tf.float32)),\n",
    "            'out_mean': tf.Variable(tf.zeros([n_input], dtype=tf.float32)),\n",
    "            'out_log_sigma': tf.Variable(tf.zeros([n_input], dtype=tf.float32))}\n",
    "        self.weights = all_weights['weights_gener']\n",
    "        self.biases = all_weights['biases_gener']\n",
    "        return all_weights\n",
    "            \n",
    "    def _recognition_network(self, weights, biases):\n",
    "        # Generate probabilistic encoder (recognition network), which\n",
    "        # maps inputs onto mean and log_sigma_sq vector of a normal distribution in latent space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.x, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        z_mean = tf.add(tf.matmul(layer_2, weights['out_mean']),\n",
    "                        biases['out_mean']) # \n",
    "        z_log_sigma_sq = \\\n",
    "            tf.add(tf.matmul(layer_2, weights['out_log_sigma']), \n",
    "                   biases['out_log_sigma'])\n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "\n",
    "    def _generator_network(self, weights, biases):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto mean param of Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, weights['h1']), \n",
    "                                           biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, weights['h2']), \n",
    "                                           biases['b2'])) \n",
    "        x_reconstr_mean = \\\n",
    "            tf.nn.sigmoid(tf.add(tf.matmul(layer_2, weights['out_mean']), \n",
    "                                 biases['out_mean']))\n",
    "        return x_reconstr_mean\n",
    "            \n",
    "    def _create_loss_optimizer(self):\n",
    "        # The loss is composed of two terms:\n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluatio of log(0.0)\n",
    "        reconstr_loss = \\\n",
    "            -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           1)\n",
    "        # reduce_sum(x,1) is summing the rows of x (i.e. summing across input dim)\n",
    "        # * is elementwise multiplication\n",
    "        \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq \n",
    "                                           - tf.square(self.z_mean) \n",
    "                                           - tf.exp(self.z_log_sigma_sq), 1)\n",
    "        self.cost = tf.reduce_mean(reconstr_loss + latent_loss)   # average over batch\n",
    "        # Use ADAM optimizer\n",
    "        self.optimizer = \\\n",
    "            tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "    def partial_fit(self, X):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer, self.cost), \n",
    "                                  feed_dict={self.x: X})\n",
    "        return cost\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian distribution\n",
    "        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n",
    "    \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian(Bernoulli?) distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})\n",
    "    \n",
    "    def test_cost(self, X):\n",
    "        \"\"\" Return cost of mini-batch without further training. \"\"\"\n",
    "        return self.sess.run(self.cost,feed_dict={self.x: X})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(network_architecture, learning_rate=0.001,\n",
    "          batch_size=100, training_epochs=10, display_step=5, transfer_fct=tf.nn.softplus):\n",
    "    vae = VariationalAutoencoder(network_architecture, \n",
    "                                 learning_rate=learning_rate, \n",
    "                                 batch_size=batch_size,transfer_fct=transfer_fct)\n",
    "    # Training cycle\n",
    "    np.random.seed(0)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        testcost=0.\n",
    "        total_train_batch = int(n_train_samples / batch_size)\n",
    "        # total_valid_batch = int(n_valid_samples / batch_size)\n",
    "        total_test_batch = int(n_test_samples / batch_size)\n",
    "        # total_batch = total_train_batch + total_valid_batch\n",
    "        # Loop over all batches\n",
    "        for i in range(total_train_batch):\n",
    "            #if i < total_train_batch:\n",
    "            batch_xs, _ , _ = mnist.train.next_batch(batch_size)\n",
    "            #else:\n",
    "            #    batch_xs, _ = mnist.validation.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            batch_xs = bernoullisample(batch_xs)\n",
    "            \n",
    "            cost = vae.partial_fit(batch_xs)\n",
    "            # Compute average training ELBO\n",
    "            avg_cost += cost / n_train_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            for i in range(total_test_batch):\n",
    "                batch_xs, _ , _ = mnist.test.next_batch(batch_size)\n",
    "                batch_xs = bernoullisample(batch_xs)\n",
    "                testcost += vae.test_cost(batch_xs) / n_test_samples * batch_size\n",
    "                \n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \\\n",
    "                  \"trainELBO=\", \"{:.9f}\".format(avg_cost), \\\n",
    "                  \"testELBO=\", \"{:.9f}\".format(testcost)\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 trainELBO= 168.300846474 testELBO= 133.073907318\n",
      "Epoch: 0002 trainELBO= 122.565420643 testELBO= 115.606456985\n",
      "Epoch: 0003 trainELBO= 113.752744779 testELBO= 110.342779236\n",
      "Epoch: 0004 trainELBO= 109.246259890 testELBO= 106.794683151\n",
      "Epoch: 0005 trainELBO= 106.749362238 testELBO= 105.236479950\n"
     ]
    }
   ],
   "source": [
    "network_architecture = \\\n",
    "    dict(n_hidden_recog_1=500, # 1st layer encoder neurons\n",
    "         n_hidden_recog_2=500, # 2nd layer encoder neurons\n",
    "         n_hidden_gener_1=500, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "         n_input=784, # MNIST data input (img shape: 28*28)\n",
    "         n_z=20)  # dimensionality of latent space\n",
    "\n",
    "#CUDA_VISIBLE_DEVICES=1,2,4,6,7\n",
    "vae = train(network_architecture, training_epochs=5, display_step=1, transfer_fct=tf.nn.relu)\n",
    "#vae.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# reinitialize mnist ordering\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\")\n",
    "binarized_images = bernoullisample(mnist.train.images)\n",
    "z_mean,z_log_sigma_sq= \\\n",
    "vae.sess.run((vae.z_mean,vae.z_log_sigma_sq) \\\n",
    "             ,feed_dict={vae.x: binarized_images})\n",
    "g_weights = vae.sess.run(vae.weights)\n",
    "g_biases = vae.sess.run(vae.biases)\n",
    "params = dict()\n",
    "params[\"mu\"] = z_mean.flatten()\n",
    "params[\"log_sigma_sq\"]=z_log_sigma_sq.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.805304552\n"
     ]
    }
   ],
   "source": [
    "avg_cost = 0.\n",
    "batch_size = vae.batch_size\n",
    "total_train_batch = int(n_train_samples / batch_size)\n",
    "for i in range(total_train_batch):\n",
    "    #if i < total_train_batch:\n",
    "    batch_xs, _ , _ = mnist.train.next_batch(batch_size)\n",
    "    batch_xs = bernoullisample(batch_xs)\n",
    "            \n",
    "    cost = vae.sess.run(vae.cost,feed_dict={vae.x: batch_xs})\n",
    "    # Compute average training ELBO\n",
    "    avg_cost += cost / n_train_samples * batch_size\n",
    "    \n",
    "print avg_cost\n",
    "vae.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class npVariationalAutoencoder(object):\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "    \n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian \n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "    \n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \"\"\"\n",
    "    def __init__(self, network_architecture, params, weights, biases, transfer_fct=tf.nn.softplus, \n",
    "                 learning_rate=0.001, batch_size=100):\n",
    "        self.network_architecture = network_architecture\n",
    "        self.transfer_fct = transfer_fct\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # tf Graph input (placeholder objects can only be used as input, and can't be evaluated)\n",
    "        self.x = tf.placeholder(tf.float32, [None, network_architecture[\"n_input\"]])\n",
    "        \n",
    "        # placeholder object for indices of params in recog net\n",
    "        # corresponding to  minibatch (use 0 indexing)\n",
    "        self.idx = tf.placeholder(tf.int32, [batch_size*network_architecture[\"n_z\"]])\n",
    "        \n",
    "        # Create autoencoder network\n",
    "        self._create_network(params,weights,biases)\n",
    "        # Define loss function based variational upper-bound and \n",
    "        # corresponding optimizer\n",
    "        self._create_loss()\n",
    "        \n",
    "        # Initializing the tensor flow variables\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "        # Launch the session\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init) #run __init__ function\n",
    "    \n",
    "    def _create_network(self, params, weights, biases):\n",
    "        # Initialize autoencode network weights and biases\n",
    "        self._initialize_weights(params, weights, biases)\n",
    "        # this feeds in the values of self.network_architecture as arguments to _initialize_weights\n",
    "        \n",
    "        # Use recognition network to determine mean and \n",
    "        # (log) variance of Gaussian distribution in latent\n",
    "        # space\n",
    "        n_z = self.network_architecture[\"n_z\"]\n",
    "        n_samples = self.network_architecture[\"n_samples\"]\n",
    "        self.z_mean, self.z_log_sigma_sq = \\\n",
    "            self._recognition_network(n_z,n_samples)\n",
    "\n",
    "        # Draw one sample z from Gaussian distribution\n",
    "        # n_z is dimensionality of latent space\n",
    "        eps = tf.random_normal((self.batch_size, n_z), 0, 1, \n",
    "                               dtype=tf.float32)\n",
    "        # z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, \n",
    "                        tf.mul(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n",
    "\n",
    "        # Use generator to determine mean of\n",
    "        # Bernoulli distribution of reconstructed input\n",
    "        self.x_reconstr_mean = \\\n",
    "            self._generator_network()\n",
    "            \n",
    "    def _initialize_weights(self, params, weights, biases):\n",
    "        # initialize weights, stored in dictionary all_weights (member of VAE class)\n",
    "        # these are all the variables that will be learned\n",
    "        # Use Xaiver init for weights, 0 for biases\n",
    "        all_weights = dict()\n",
    "        all_weights['params_recog'] = {\n",
    "            'mu': tf.Variable(params['mu']),\n",
    "            'log_sigma_sq': tf.Variable(params['log_sigma_sq'])}\n",
    "            # stack each column of params(n_z by n_samples) into one column vector\n",
    "        all_weights['weights_gener'] = {\n",
    "            'h1': tf.Variable(weights['h1']),\n",
    "            'h2': tf.Variable(weights['h2']),\n",
    "            'out_mean': tf.Variable(weights['out_mean']),\n",
    "            'out_log_sigma': tf.Variable(weights['out_log_sigma'])}\n",
    "        all_weights['biases_gener'] = {\n",
    "            'b1': tf.Variable(biases['b1']),\n",
    "            'b2': tf.Variable(biases['b2']),\n",
    "            'out_mean': tf.Variable(biases['out_mean']),\n",
    "            'out_log_sigma': tf.Variable(biases['out_log_sigma'])}\n",
    "        self.params=all_weights['params_recog']\n",
    "        self.weights=all_weights['weights_gener']\n",
    "        self.biases=all_weights['biases_gener']\n",
    "            \n",
    "    def _recognition_network(self, n_z, n_samples):\n",
    "        # The approximate posterior distribution, which is a fully factorized Gaussian \n",
    "        # in the latent variables.\n",
    "        # Output mean and log_sigma_sq of z_n for the minibatch given by self.idx\n",
    "        z_mean = tf.reshape(tf.gather(self.params['mu'],self.idx),[-1,n_z])\n",
    "        z_log_sigma_sq = tf.reshape(tf.gather(self.params['log_sigma_sq'],self.idx),[-1,n_z])\n",
    "        return (z_mean, z_log_sigma_sq)\n",
    "\n",
    "    def _generator_network(self):\n",
    "        # Generate probabilistic decoder (decoder network), which\n",
    "        # maps points in latent space onto mean param of Bernoulli distribution in data space.\n",
    "        # The transformation is parametrized and can be learned.\n",
    "        layer_1 = self.transfer_fct(tf.add(tf.matmul(self.z, self.weights['h1']), \n",
    "                                           self.biases['b1'])) \n",
    "        layer_2 = self.transfer_fct(tf.add(tf.matmul(layer_1, self.weights['h2']), \n",
    "                                           self.biases['b2'])) \n",
    "        x_reconstr_mean = \\\n",
    "            tf.nn.sigmoid(tf.add(tf.matmul(layer_2, self.weights['out_mean']), \n",
    "                                 self.biases['out_mean']))\n",
    "        return x_reconstr_mean\n",
    "            \n",
    "    def _create_loss(self):\n",
    "        # The loss is composed of two terms:\n",
    "        # 1.) The reconstruction loss (the negative log probability\n",
    "        #     of the input under the reconstructed Bernoulli distribution \n",
    "        #     induced by the decoder in the data space).\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for reconstructing the input when the activation in latent\n",
    "        #     is given.\n",
    "        # Adding 1e-10 to avoid evaluatio of log(0.0)\n",
    "        reconstr_loss = \\\n",
    "            -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_reconstr_mean)\n",
    "                           + (1-self.x) * tf.log(1e-10 + 1 - self.x_reconstr_mean),\n",
    "                           1)\n",
    "        # reduce_sum(x,1) is summing the rows of x (i.e. summing across input dim)\n",
    "        # * is elementwise multiplication\n",
    "        \n",
    "        # 2.) The latent loss, which is defined as the Kullback Leibler divergence \n",
    "        ##    between the distribution in latent space induced by the encoder on \n",
    "        #     the data and some prior. This acts as a kind of regularizer.\n",
    "        #     This can be interpreted as the number of \"nats\" required\n",
    "        #     for transmitting the the latent space distribution given\n",
    "        #     the prior.\n",
    "        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq \n",
    "                                           - tf.square(self.z_mean) \n",
    "                                           - tf.exp(self.z_log_sigma_sq), 1)\n",
    "        self.reconstr = tf.reduce_mean(reconstr_loss)\n",
    "        self.latent = tf.reduce_mean(latent_loss)\n",
    "        self.cost = self.reconstr + self.latent # average over batch\n",
    "\n",
    "        # Use ADAM optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate)\n",
    "        grads_and_vars=optimizer.compute_gradients(self.cost)\n",
    "        grads_and_vars = [(g,v) for g,v in grads_and_vars if g is not None]\n",
    "        cgv = [(tf.clip_by_value(gv[0],-1.,1.),gv[1]) for gv in grads_and_vars]\n",
    "        self.optimizer = optimizer.apply_gradients(cgv)\n",
    "        \n",
    "    def partial_fit(self, X, myidx):\n",
    "        \"\"\"Train model based on mini-batch of input data.\n",
    "        \n",
    "        Return cost of mini-batch.\n",
    "        \"\"\"\n",
    "        opt, cost = self.sess.run((self.optimizer,self.cost), \\\n",
    "                        feed_dict={self.x: X, self.idx: myidx})\n",
    "        return cost\n",
    "    \n",
    "    def generate(self, z_mu=None):\n",
    "        \"\"\" Generate data by sampling from latent space.\n",
    "        \n",
    "        If z_mu is not None, data for this point in latent space is\n",
    "        generated. Otherwise, z_mu is drawn from prior in latent \n",
    "        space.        \n",
    "        \"\"\"\n",
    "        if z_mu is None:\n",
    "            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n",
    "        # Note: This maps to mean of distribution, we could alternatively\n",
    "        # sample from Gaussian(Bernoulli?) distribution\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.z: z_mu})\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        \"\"\" Use VAE to reconstruct given data. \"\"\"\n",
    "        return self.sess.run(self.x_reconstr_mean, \n",
    "                             feed_dict={self.x: X})\n",
    "    \n",
    "    def test_cost(self, X):\n",
    "        \"\"\" Return cost of mini-batch without further training. \"\"\"\n",
    "        return self.sess.run(self.cost,feed_dict={self.x: X})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nptrain(npvae,training_epochs=10, display_step=5):\n",
    "    batch_size = npvae.batch_size\n",
    "    n_z = npvae.network_architecture[\"n_z\"]\n",
    "    # Training cycle\n",
    "    np.random.seed(0)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        testcost=0.\n",
    "        total_train_batch = int(n_train_samples / batch_size)\n",
    "        # total_valid_batch = int(n_valid_samples / batch_size)\n",
    "        total_test_batch = int(n_test_samples / batch_size)\n",
    "        # total_batch = total_train_batch + total_valid_batch\n",
    "        # Loop over all batches\n",
    "        for i in range(total_train_batch):\n",
    "            #if i < total_train_batch:\n",
    "            batch_xs, _ , batch_idx = mnist.train.next_batch(batch_size)\n",
    "            #else:\n",
    "            #    batch_xs, _ = mnist.validation.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            batch_xs = bernoullisample(batch_xs)\n",
    "            idx = convert_col_idx(n_z,batch_idx) \n",
    "                \n",
    "            cost = npvae.partial_fit(batch_xs, idx)\n",
    "            # print \"trainELBO=\", \"{:.9f}\".format(cost)\n",
    "            # Compute average training ELBO\n",
    "            avg_cost += cost / n_train_samples * batch_size\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            #for i in range(total_test_batch):\n",
    "            #    batch_xs, _ = mnist.test.next_batch(batch_size)\n",
    "            #    batch_xs = bernoullisample(batch_xs)\n",
    "            #    testcost += vae.test_cost(batch_xs) / n_test_samples * batch_size\n",
    "                \n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \\\n",
    "                  \"trainELBO=\", \"{:.9f}\".format(avg_cost)\n",
    "    return vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npvae.sess.close()\n",
    "network_architecture = \\\n",
    "    dict(n_samples=n_train_samples, # number of training data points\n",
    "         n_hidden_gener_1=500, # 1st layer decoder neurons\n",
    "         n_hidden_gener_2=500, # 2nd layer decoder neurons\n",
    "         n_input=784, # MNIST data input (img shape: 28*28)\n",
    "         n_z=20) \n",
    "\n",
    "npvae = npVariationalAutoencoder(network_architecture, \\\n",
    "                                 params,g_weights,g_biases, \\\n",
    "                               learning_rate=0.001, \\\n",
    "                               batch_size=100,\\\n",
    "                               transfer_fct=tf.nn.relu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 trainELBO= 109.920894831\n",
      "Epoch: 0002 trainELBO= 108.588261233\n",
      "Epoch: 0003 trainELBO= 107.524732583\n",
      "Epoch: 0004 trainELBO= 106.675070482\n",
      "Epoch: 0005 trainELBO= 105.821501354\n",
      "Epoch: 0006 trainELBO= 105.219442569\n",
      "Epoch: 0007 trainELBO= 104.662532598\n",
      "Epoch: 0008 trainELBO= 104.081343758\n",
      "Epoch: 0009 trainELBO= 103.628838876\n",
      "Epoch: 0010 trainELBO= 103.235594677\n"
     ]
    }
   ],
   "source": [
    "npvae = nptrain(npvae,training_epochs=10,display_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-9341ebeeb2c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "_sample = mnist.test.next_batch(100)[0]\n",
    "x_reconstruct = vae.reconstruct(x_sample)\n",
    "\n",
    "plt.figure(figsize=(8, 12))\n",
    "for i in range(5):\n",
    "\n",
    "    plt.subplot(5, 2, 2*i + 1)\n",
    "    plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=1)\n",
    "    plt.title(\"Test input\")\n",
    "    plt.colorbar()\n",
    "    plt.subplot(5, 2, 2*i + 2)\n",
    "    plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=1)\n",
    "    plt.title(\"Reconstruction\")\n",
    "    plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "a=np.empty(4,dtype=int);\n",
    "idx=tf.Variable(a,dtype=tf.int32)\n",
    "init = tf.initialize_all_variables()\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "print sess.run(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
